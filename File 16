import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow import keras
from tensorflow.keras import layers

# --------- Synthetic Data Generation ---------
def generate_synthetic_data(num_samples):
    np.random.seed(0)
    
    # Topographic Data
    elevation = np.random.normal(loc=100, scale=20, size=num_samples)  # Elevation
    slope = np.random.uniform(low=0, high=45, size=num_samples)         # Slope in degrees
    aspect = np.random.uniform(low=0, high=360, size=num_samples)       # Aspect in degrees
    
    # Soil Data
    soil_moisture = np.random.uniform(low=0, high=100, size=num_samples) # Soil Moisture
    cohesion = np.random.normal(loc=20, scale=5, size=num_samples)       # Cohesion
    
    # Randomly assign stability (1 = stable, 0 = unstable)
    stability = (elevation + slope + cohesion) > 150  # A simple synthetic condition
    stability = stability.astype(int)  # Convert boolean to int
    
    # Creating DataFrame
    data = pd.DataFrame({
        'Elevation': elevation,
        'Slope': slope,
        'Aspect': aspect,
        'Soil_Moisture': soil_moisture,
        'Cohesion': cohesion,
        'Stability': stability
    })
  
    return data

# Generate synthetic data
data = generate_synthetic_data(1000)

# --------- Data Preprocessing ---------
# Split features and labels
X = data.drop('Stability', axis=1)
y = data['Stability']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# --------- Build a Simple Neural Network ---------
model = keras.Sequential([
    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    layers.Dense(64, activation='relu'),
    layers.Dense(1, activation='sigmoid')  # Output layer for binary classification
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# --------- Train the Model ---------
model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)

# --------- Evaluate the Model ---------
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test Accuracy: {accuracy:.4f}')

# --------- Make Predictions ---------
predictions = (model.predict(X_test) > 0.5).astype("int32")
print(f'Predicted Classes: {predictions.flatten()}')
